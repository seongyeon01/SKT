{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m'skt_yeon (Python 3.8.0)'(으)로 셀을 실행하려면 ipykernel 패키지가 필요합니다.\n",
      "\u001b[1;31m다음 명령어를 실행하여 Python 환경에 'ipykernel'을(를) 설치합니다. \n",
      "\u001b[1;31m 명령: 'conda install -n skt_yeon ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from CLS_ring import CLSforRing\n",
    "from utils import load_and_resample, extract_sec, preprocess, forpred\n",
    "import torch\n",
    "import ring_voice\n",
    "from prediction_denoise import prediction\n",
    "device = torch.device('cuda:1')\n",
    "model = ring_voice.model\n",
    "model.load_state_dict(torch.load(\"/home/ubuntu/jupyter/SKT/log/ring_voice_binary_2/model.pt\"))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# 코덱별 샘플링 레이트 및 주파수 범위 설정\n",
    "codec_config = {\n",
    "    'EVS': {'sample_rate': 16000, 'freq_range': (0, 8000)},\n",
    "    'AMR-WB': {'sample_rate': 16000, 'freq_range': (0, 8000)},\n",
    "    'AMR': {'sample_rate': 8000, 'freq_range': (0, 4000)},\n",
    "}\n",
    "selected_codec = 'EVS'\n",
    "config = codec_config[selected_codec]\n",
    "target_sr = config['sample_rate']\n",
    "n_fft = 1024  # FFT 크기\n",
    "hop_length = n_fft // 4  # 일반적으로 hop_length는 n_fft의 1/4로 설정\n",
    "hann_window = torch.hann_window(n_fft)\n",
    "\n",
    "weights_path = '/home/ubuntu/jupyter/SKT/submit/weights'\n",
    "name_model = 'model_unet'\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "\n",
    "test_sample1_path = \"/home/ubuntu/jupyter/SKT/data/Scenario/music.wav\"\n",
    "test_sample2_path = \"/home/ubuntu/jupyter/SKT/data/Scenario/system_o.wav\" # PCM_30_wb\n",
    "test_sample3_path = \"/home/ubuntu/jupyter/SKT/data/Scenario/system_x1.wav\" # PCM_15_wb\n",
    "\n",
    "test_sample4_path = \"/home/ubuntu/jupyter/SKT/data/Scenario/music+speech.wav\"\n",
    "test_sample5_path = \"/home/ubuntu/jupyter/SKT/data/Scenario/music+speech(noise).wav\"\n",
    "\n",
    "test_sample6_path = \"/home/ubuntu/jupyter/SKT/data/Scenario/system_o+speech.wav\" # ANNC_1508_wb + start @ 60sec\n",
    "test_sample7_path = \"/home/ubuntu/jupyter/SKT/data/Scenario/system_o+speech(noise).wav\" # INTL_TERM_ANM_wb + start @ 4sec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in [test_sample1_path, test_sample2_path, test_sample3_path, test_sample4_path, test_sample5_path, test_sample6_path, test_sample7_path]:\n",
    "    print(\"\\n\",path)\n",
    "    sample = load_and_resample(path, target_sr)\n",
    "    RING = CLSforRing('RF')\n",
    "    for s in range(0, sample.shape[-1]- target_sr, target_sr):\n",
    "        sample_sec = extract_sec(sample, target_sr, start = int(s/target_sr))\n",
    "        sample_filter = preprocess(sample_sec, n_fft, hop_length, hann_window, target_sr, config['freq_range']).float()\n",
    "        is_sys = RING.cls(sample_filter.reshape(1,-1))\n",
    "        if is_sys == 'no sys':\n",
    "            with torch.no_grad():\n",
    "                out_dict = model(forpred(sample_filter.unsqueeze(0)).unsqueeze(0).type(torch.FloatTensor).transpose(2,3).to(device))\n",
    "            test_pred=out_dict['event_logit']\n",
    "            no_speech = torch.argmax(test_pred, dim = -1).item()\n",
    "            if no_speech:\n",
    "                print(f\"{int(s/target_sr)} : {int(s/target_sr)+1} - music\") \n",
    "            else:\n",
    "                print(f\"{int(s/target_sr)} : {int(s/target_sr)+1} - speech\")\n",
    "                truncated_sample = sample[:, s:]\n",
    "                #######################\n",
    "                ### Enhancement\n",
    "                #######################\n",
    "                # 경로 및 파라미터들 직접 작성\n",
    "                \n",
    "                audio_dir_prediction = '/home/ubuntu/jupyter/minyoung/skt/Speech-enhancement/demo_data/test'\n",
    "                dir_save_prediction = '/home/ubuntu/jupyter/minyoung/skt/Speech-enhancement/demo_data/test/sample_denoise/'\n",
    "                audio_input_prediction = [truncated_sample]\n",
    "                audio_output_prediction = 'sample32_denoise.wav'\n",
    "                # Prediction 및 enhancement 단계\n",
    "                prediction(weights_path, name_model, audio_dir_prediction, dir_save_prediction,\n",
    "                            audio_input_prediction, audio_output_prediction, 8000, 1.0,\n",
    "                            8064, 8064, 255, 63)\n",
    "\n",
    "        else:\n",
    "            print(f\"{int(s/target_sr)} : {int(s/target_sr)+1} - {is_sys}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adgadg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pydub import AudioSegment\n",
    "# import os\n",
    "\n",
    "# def split_audio(file_path, output_folder, split_length_ms=1000):\n",
    "#     # 오디오 파일 로드\n",
    "#     audio = AudioSegment.from_file(file_path)\n",
    "\n",
    "#     # 전체 길이 계산 (밀리초 단위)\n",
    "#     total_length_ms = len(audio)\n",
    "\n",
    "#     # 출력을 저장할 폴더가 없다면 생성\n",
    "#     if not os.path.exists(output_folder):\n",
    "#         os.makedirs(output_folder)\n",
    "\n",
    "#     # 1초 단위로 오디오 자르기\n",
    "#     for i in range(0, total_length_ms, split_length_ms):\n",
    "#         split_audio = audio[i:i+split_length_ms]\n",
    "#         # 파일 저장 (0001, 0002 형식으로 저장)\n",
    "#         split_filename = os.path.join(output_folder, f\"split_{i//split_length_ms:04d}.wav\")\n",
    "#         split_audio.export(split_filename, format=\"wav\")\n",
    "#         print(f\"저장됨: {split_filename}\")\n",
    "\n",
    "# # 예시 사용법\n",
    "# for file_path in [test_sample2_path, test_sample3_path, test_sample4_path, test_sample5_path, test_sample6_path, test_sample7_path]:\n",
    "#     os.makedirs(f\"/home/ubuntu/jupyter/SKT/submit/samples/{os.path.basename(file_path)[:-4]}\", exist_ok = True)\n",
    "#     output_folder = f\"/home/ubuntu/jupyter/SKT/submit/samples/{os.path.basename(file_path)[:-4]}\"\n",
    "#     split_audio(file_path, output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pydub import AudioSegment\n",
    "# import os\n",
    "# ring_path = \"/home/ubuntu/jupyter/SKT/data/ring\"\n",
    "# ring_list = os.listdir(ring_path)\n",
    "\n",
    "# def split_audio(file_path, output_folder, split_length_ms=1000):\n",
    "#     # 오디오 파일 로드\n",
    "#     audio = AudioSegment.from_file(file_path)\n",
    "\n",
    "#     # 전체 길이 계산 (밀리초 단위)\n",
    "#     total_length_ms = len(audio)\n",
    "\n",
    "#     # 출력을 저장할 폴더가 없다면 생성\n",
    "#     if not os.path.exists(output_folder):\n",
    "#         os.makedirs(output_folder)\n",
    "\n",
    "#     # 1초 단위로 오디오 자르기\n",
    "#     for i in range(0, total_length_ms, split_length_ms):\n",
    "#         split_audio = audio[i:i+split_length_ms]\n",
    "#         # 파일 저장 (0001, 0002 형식으로 저장)\n",
    "#         split_filename = os.path.join(output_folder, f\"{os.path.basename(file_path)[:-4]}{i//split_length_ms:04d}.wav\")\n",
    "#         split_audio.export(split_filename, format=\"wav\")\n",
    "#         print(f\"저장됨: {split_filename}\")\n",
    "\n",
    "# # 예시 사용법\n",
    "# for file_path in ring_list:\n",
    "#     output_folder = f\"/home/ubuntu/jupyter/SKT/data/ring_split\"\n",
    "#     os.makedirs(output_folder, exist_ok = True)\n",
    "#     split_audio(f\"{ring_path}/{file_path}\", output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import pickle\n",
    "# from tqdm.notebook import tqdm\n",
    "# ring_path = f\"/home/ubuntu/jupyter/SKT/data/ring_split\" # path for system ringbacktone\n",
    "# ring_list = [f\"{ring_path}/{w}\" for w in os.listdir(ring_path)] # 1초 이하 제거\n",
    "# # ring2idx = {r:i for i, r in enumerate(ring_list)}\n",
    "# # idx2ring = {i:os.path.basename(r) for i, r in enumerate(ring_list)}\n",
    "\n",
    "# ring_specs = []\n",
    "# idx2ring = {}\n",
    "# i = 0\n",
    "# for r in tqdm(ring_list):\n",
    "#     ring_sec = load_and_resample(r, target_sr)\n",
    "#     print(ring_sec.shape)\n",
    "#     try:\n",
    "#         ring_filter = preprocess(ring_sec, n_fft, hop_length, hann_window, target_sr, config['freq_range']).float()\n",
    "#     except:\n",
    "#         continue\n",
    "#     spec = torch.zeros([513, 63])\n",
    "#     spec[:,:ring_filter.shape[-1]] = ring_filter.squeeze()\n",
    "#     ring_specs.append(spec)\n",
    "#     idx2ring[i] = '_'.join(os.path.basename(r)[:-4].split('_')[:-1])\n",
    "#     i+=1\n",
    "\n",
    "# # np.save('ring_label2.npy', np.array(labels))\n",
    "# np.save('ring_spec2.npy', torch.stack(ring_specs).numpy())\n",
    "# with open('idx2ring2.pickle','wb') as fw:\n",
    "#     pickle.dump(idx2ring, fw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from prediction_denoise import prediction\n",
    "# import os\n",
    "# import numpy as np\n",
    "# import librosa\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "# weights_path = '/home/ubuntu/jupyter/SKT/submit/weights'\n",
    "# name_model = 'model_unet'\n",
    "\n",
    "\n",
    "# sample_dir = \"/home/ubuntu/jupyter/SKT/submit/samples\"\n",
    "# test_list = os.listdir(sample_dir)\n",
    "\n",
    "# for test_folder in test_list:\n",
    "#     print('\\n',test_folder)\n",
    "\n",
    "#     # 링백톤 분류기 불러오기\n",
    "#     RING = CLSforRing()\n",
    "#     # 1초 단위로 wav 파일 불러오기\n",
    "#     ## 1초 단위 wav list\n",
    "#     test_samples = sorted(os.listdir(f\"{sample_dir}/{test_folder}\"))\n",
    "#     s = 0\n",
    "#     for path in test_samples:\n",
    "#         sample_sec = load_and_resample(f\"{sample_dir}/{test_folder}/{path}\", target_sr)\n",
    "#         sample_filter = torch.empty([513, 63])\n",
    "#         sample_filter_ = preprocess(sample_sec, n_fft, hop_length, hann_window, target_sr, config['freq_range']).float()\n",
    "#         sample_filter[:,:sample_filter_.shape[-1]] = sample_filter_\n",
    "#         is_sys = RING.cls(sample_filter.reshape(1,-1))\n",
    "#         if is_sys == 'no sys':\n",
    "#             with torch.no_grad():\n",
    "#                 out_dict = model(forpred(sample_filter.unsqueeze(0)).unsqueeze(0).type(torch.FloatTensor).transpose(2,3).to(device))\n",
    "#             test_pred=out_dict['event_logit']\n",
    "#             no_speech = torch.argmax(test_pred, dim = -1).item()\n",
    "#             if no_speech:\n",
    "#                 print(f\"{s} : {s+1} - music\") \n",
    "#             else:\n",
    "#                 print(f\"{s} : {s+1} - speech\")\n",
    "#                 #######################\n",
    "#                 ### Enhancement\n",
    "#                 #######################\n",
    "#                 # 경로 및 파라미터들 직접 작성\n",
    "#                 audio_dir_prediction = f\"{sample_dir}/{test_folder}/\"\n",
    "#                 dir_save_prediction = audio_dir_prediction.replace('samples','enhance')\n",
    "#                 audio_input_prediction = [path]\n",
    "#                 audio_output_prediction = path\n",
    "#                 # Prediction 및 enhancement 단계\n",
    "#                 prediction(weights_path, name_model, audio_dir_prediction, dir_save_prediction,\n",
    "#                             audio_input_prediction, audio_output_prediction, 8000, 1.0,\n",
    "#                             8064, 8064, 255, 63)\n",
    "#         else:\n",
    "#             print(f\"{s} : {s+1} - {is_sys}\") \n",
    "#         s += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skt_yeon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
